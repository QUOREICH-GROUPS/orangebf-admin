# Fonctionnalit√©s Vocales - RAG Orange Burkina Faso

Ce document d√©crit l'int√©gration des fonctionnalit√©s vocales OpenAI (Whisper + TTS) dans le chatbot RAG.

## üéØ Fonctionnalit√©s

Le serveur RAG int√®gre maintenant trois endpoints vocaux :

1. **`/transcribe`** - Speech-to-Text (Whisper)
2. **`/speak`** - Text-to-Speech
3. **`/voice-chat`** - Chat vocal complet (audio ‚Üí r√©ponse audio)

## ‚öôÔ∏è Configuration

### 1. Installer les d√©pendances

```bash
pip install openai python-dotenv
```

### 2. Configurer la cl√© API OpenAI

Cr√©ez un fichier `.env` √† la racine du projet :

```bash
cp .env.example .env
```

√âditez le fichier `.env` et ajoutez votre cl√© API OpenAI :

```bash
OPENAI_API_KEY=sk-proj-votre_cl√©_ici
```

Obtenez votre cl√© API sur : https://platform.openai.com/api-keys

### 3. D√©marrer le serveur

```bash
uvicorn data_processing.rag_server_gpt4all:app --reload
```

Le serveur d√©marre sur `http://localhost:8000`

## üì° Utilisation des Endpoints

### 1. `/transcribe` - Transcription audio en texte

**M√©thode:** POST
**Content-Type:** multipart/form-data
**Fichiers support√©s:** mp3, mp4, mpeg, mpga, m4a, wav, webm (max 25MB)

**Exemple avec curl:**
```bash
curl -X POST "http://localhost:8000/transcribe" \
  -F "file=@question.mp3"
```

**R√©ponse:**
```json
{
  "text": "Comment activer Orange Money ?",
  "filename": "question.mp3"
}
```

**Exemple Python:**
```python
import requests

with open("question.mp3", "rb") as f:
    files = {"file": ("question.mp3", f, "audio/mpeg")}
    response = requests.post("http://localhost:8000/transcribe", files=files)
    print(response.json()["text"])
```

---

### 2. `/speak` - Conversion texte en audio

**M√©thode:** POST
**Content-Type:** application/json
**Retour:** Fichier MP3

**Param√®tres:**
- `text` (string, requis) : Le texte √† convertir en audio
- `voice` (string, optionnel) : La voix √† utiliser (d√©faut: "nova")
  - Options: `alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer`

**Exemple avec curl:**
```bash
curl -X POST "http://localhost:8000/speak" \
  -H "Content-Type: application/json" \
  -d '{"text": "Bonjour, bienvenue chez Orange Burkina Faso", "voice": "nova"}' \
  --output response.mp3
```

**Exemple Python:**
```python
import requests

payload = {
    "text": "Pour activer Orange Money, composez le *144#",
    "voice": "nova"
}

response = requests.post("http://localhost:8000/speak", json=payload)

with open("response.mp3", "wb") as f:
    f.write(response.content)
```

---

### 3. `/voice-chat` - Chat vocal complet

**M√©thode:** POST
**Content-Type:** multipart/form-data
**Retour:** Fichier MP3 (r√©ponse audio)

Cet endpoint combine tout le pipeline :
1. Transcrit votre question audio en texte (Whisper)
2. Recherche le contexte pertinent dans la base de donn√©es (FAISS)
3. G√©n√®re une r√©ponse avec le mod√®le RAG (GPT4All)
4. Convertit la r√©ponse en audio (OpenAI TTS)

**Headers de r√©ponse:**
- `X-Question-Text` : Votre question transcrite
- `X-Response-Text` : D√©but de la r√©ponse textuelle (200 premiers caract√®res)

**Exemple avec curl:**
```bash
curl -X POST "http://localhost:8000/voice-chat" \
  -F "file=@question.mp3" \
  -o chat_response.mp3 \
  -v
```

**Exemple Python:**
```python
import requests

with open("question.mp3", "rb") as f:
    files = {"file": ("question.mp3", f, "audio/mpeg")}
    response = requests.post("http://localhost:8000/voice-chat", files=files)

# R√©cup√©rer les informations dans les headers
question = response.headers.get("X-Question-Text")
answer_preview = response.headers.get("X-Response-Text")

print(f"Question: {question}")
print(f"R√©ponse: {answer_preview}")

# Sauvegarder l'audio
with open("chat_response.mp3", "wb") as f:
    f.write(response.content)
```

---

## üß™ Script de Test

Un script de test complet est fourni : `test_voice_api.py`

### Exemples d'utilisation

```bash
# V√©rifier que le serveur est en ligne
python test_voice_api.py

# Transcrire un fichier audio
python test_voice_api.py --transcribe question.mp3

# Convertir du texte en audio
python test_voice_api.py --speak "Comment activer Orange Money?"

# Choisir une voix diff√©rente
python test_voice_api.py --speak "Bonjour" --voice shimmer --output hello.mp3

# Test complet : question audio -> r√©ponse audio
python test_voice_api.py --voice-chat question.mp3 --output reponse.mp3

# Question texte (sans voix)
python test_voice_api.py --ask "Comment activer Orange Money?"
```

---

## üé≠ Voix Disponibles (TTS)

OpenAI propose 6 voix diff√©rentes :

| Voix | Description |
|------|-------------|
| `alloy` | Voix neutre et √©quilibr√©e |
| `echo` | Voix masculine douce |
| `fable` | Voix narrative britannique |
| `onyx` | Voix masculine profonde |
| `nova` | Voix f√©minine claire (d√©faut) |
| `shimmer` | Voix f√©minine √©nergique |

Modifiez la constante `TTS_VOICE` dans `rag_server_gpt4all.py` pour changer la voix par d√©faut.

---

## üí∞ Tarification OpenAI

### Whisper (Speech-to-Text)
- **$0.006 / minute** d'audio transcrit

### TTS (Text-to-Speech)
- **TTS Standard** (`tts-1`) : $0.015 / 1K caract√®res
- **TTS HD** (`tts-1-hd`) : $0.030 / 1K caract√®res

**Exemple de co√ªt pour `/voice-chat` :**
- Question de 10 secondes : ~$0.001
- R√©ponse de 100 mots (~500 caract√®res) : ~$0.008
- **Total : ~$0.009 par interaction vocale compl√®te**

---

## üîí S√©curit√©

- Le fichier `.env` contient vos cl√©s API sensibles
- Il est automatiquement ignor√© par git (`.gitignore`)
- **NE JAMAIS** committer le fichier `.env`
- Partagez uniquement `.env.example` avec les autres d√©veloppeurs

---

## üõ†Ô∏è D√©pannage

### Erreur : "Service vocal non disponible"
‚Üí V√©rifiez que `OPENAI_API_KEY` est d√©finie dans `.env`

### Erreur : "Type de fichier non support√©"
‚Üí Assurez-vous d'envoyer un format audio support√© (mp3, wav, etc.)

### Erreur : "Invalid API key"
‚Üí V√©rifiez que votre cl√© API OpenAI est valide et active

### Le serveur ne trouve pas le fichier .env
‚Üí Assurez-vous que `.env` est √† la racine du projet et que `python-dotenv` est install√©

---

## üìö Ressources

- [Documentation OpenAI Whisper](https://platform.openai.com/docs/guides/speech-to-text)
- [Documentation OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech)
- [FastAPI Docs](https://fastapi.tiangolo.com/)

---

## üöÄ Int√©gration Frontend

### Exemple HTML/JavaScript simple

```html
<!DOCTYPE html>
<html>
<head>
    <title>Orange Voice Chat</title>
</head>
<body>
    <h1>Chat Vocal Orange</h1>

    <!-- Enregistrement audio -->
    <button id="recordBtn">üé§ Enregistrer</button>
    <button id="stopBtn" disabled>‚èπÔ∏è Arr√™ter</button>

    <!-- Lecture de la r√©ponse -->
    <audio id="responseAudio" controls></audio>

    <script>
        let mediaRecorder;
        let audioChunks = [];

        document.getElementById('recordBtn').onclick = async () => {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);

            mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);

            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/mpeg' });
                audioChunks = [];

                // Envoyer √† /voice-chat
                const formData = new FormData();
                formData.append('file', audioBlob, 'question.mp3');

                const response = await fetch('http://localhost:8000/voice-chat', {
                    method: 'POST',
                    body: formData
                });

                const responseBlob = await response.blob();
                const audioUrl = URL.createObjectURL(responseBlob);

                // Lire la r√©ponse
                document.getElementById('responseAudio').src = audioUrl;
            };

            mediaRecorder.start();
            document.getElementById('recordBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
        };

        document.getElementById('stopBtn').onclick = () => {
            mediaRecorder.stop();
            document.getElementById('recordBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        };
    </script>
</body>
</html>
```

---

**D√©velopp√© avec ‚ù§Ô∏è pour Orange Burkina Faso**
