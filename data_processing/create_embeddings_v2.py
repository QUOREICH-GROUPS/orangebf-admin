#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
create_embeddings_v2.py - CrÃ©ation d'embeddings Ã  partir des donnÃ©es nettoyÃ©es v2
"""

import json
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# Fichiers
input_file = "orange_services_clean_v2.json"
index_file = "orange_faq_v2.index"
metadata_file = "metadata_v2.json"

print("=" * 60)
print("ðŸ”§ CRÃ‰ATION DES EMBEDDINGS - VERSION 2 (DONNÃ‰ES PROPRES)")
print("=" * 60)

# Charger le modÃ¨le lÃ©ger
print("\nðŸ“¦ Chargement du modÃ¨le d'embeddings...")
print("   ModÃ¨le: sentence-transformers/all-MiniLM-L6-v2")
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
print("âœ… ModÃ¨le chargÃ©")

# Charger les paragraphes nettoyÃ©s
print(f"\nðŸ“‚ Chargement de {input_file}...")
with open(input_file, "r", encoding="utf-8") as f:
    data = json.load(f)

texts = [item["text"] for item in data if "text" in item and len(item["text"]) > 10]

print(f"âœ… {len(texts)} paragraphes chargÃ©s")
print(f"   Longueur moyenne: {sum(len(t) for t in texts) / len(texts):.0f} caractÃ¨res")

# GÃ©nÃ©rer les embeddings
print("\nðŸ”„ GÃ©nÃ©ration des embeddings...")
print("   (Cela peut prendre quelques minutes...)")
embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)
print(f"âœ… Embeddings gÃ©nÃ©rÃ©s: {embeddings.shape}")

# Normalisation pour amÃ©liorer la recherche cosine similarity
print("\nðŸ”§ Normalisation des embeddings...")
embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
print("âœ… Embeddings normalisÃ©s")

# CrÃ©er un index FAISS (IndexFlatIP = Inner Product, pour cosine similarity)
print("\nðŸ“Š CrÃ©ation de l'index FAISS...")
dimension = embeddings.shape[1]
print(f"   Dimension: {dimension}")
index = faiss.IndexFlatIP(dimension)
index.add(embeddings)
print(f"âœ… Index crÃ©Ã© avec {index.ntotal} vecteurs")

# Sauvegarder l'index
print(f"\nðŸ’¾ Sauvegarde de l'index dans {index_file}...")
faiss.write_index(index, index_file)
print("âœ… Index sauvegardÃ©")

# Sauvegarder les mÃ©tadonnÃ©es (textes)
print(f"\nðŸ’¾ Sauvegarde des mÃ©tadonnÃ©es dans {metadata_file}...")
with open(metadata_file, "w", encoding="utf-8") as f:
    json.dump(texts, f, ensure_ascii=False, indent=2)
print("âœ… MÃ©tadonnÃ©es sauvegardÃ©es")

# Statistiques finales
print("\n" + "=" * 60)
print("ðŸ“Š STATISTIQUES FINALES")
print("=" * 60)
print(f"   Paragraphes indexÃ©s: {len(texts)}")
print(f"   Dimension des vecteurs: {dimension}")
print(f"   Taille de l'index: {index.ntotal} vecteurs")
print(f"   Fichier index: {index_file}")
print(f"   Fichier metadata: {metadata_file}")
print("=" * 60)
print("âœ… INDEXATION TERMINÃ‰E AVEC SUCCÃˆS!")
print("=" * 60)

# Exemples de recherche pour vÃ©rification
print("\nðŸ§ª Test de recherche...")
test_queries = [
    "Comment consulter mon solde?",
    "Activer Orange Money",
    "Forfait internet"
]

for query in test_queries:
    q_vec = model.encode([query], convert_to_numpy=True)
    q_vec = q_vec / np.linalg.norm(q_vec, axis=1, keepdims=True)
    scores, indices = index.search(q_vec, 3)

    print(f"\nðŸ” Query: '{query}'")
    print(f"   Top 3 rÃ©sultats:")
    for i, (idx, score) in enumerate(zip(indices[0], scores[0]), 1):
        text_preview = texts[idx][:80] + "..." if len(texts[idx]) > 80 else texts[idx]
        print(f"      {i}. (score: {score:.3f}) {text_preview}")

print("\n" + "=" * 60)
print("âœ… SystÃ¨me RAG prÃªt Ã  l'emploi!")
print("=" * 60)
