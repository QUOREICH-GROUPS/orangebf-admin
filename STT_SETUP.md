# Guide d'Installation - Reconnaissance Vocale (STT)

## ğŸ¤ Trois Options STT pour Raspberry Pi 5

### Comparaison Rapide

| Moteur | QualitÃ© | Vitesse | RAM | Langues | RecommandÃ© Pour |
|--------|---------|---------|-----|---------|-----------------|
| **Whisper Tiny** | â­â­â­â­ | âš¡âš¡âš¡ | ~1GB | 99+ | **Production** |
| **Faster-Whisper** | â­â­â­â­â­ | âš¡âš¡âš¡âš¡ | ~800MB | 99+ | **Meilleur choix** |
| **Vosk** | â­â­â­ | âš¡âš¡âš¡âš¡âš¡ | ~200MB | LimitÃ© | Ressources faibles |

---

## ğŸ“¦ Option 1: Faster-Whisper â­ **RECOMMANDÃ‰**

Whisper optimisÃ© avec CTranslate2, **4x plus rapide** que Whisper standard!

### Avantages:
- âœ… Excellente qualitÃ© (mÃªme niveau que Whisper)
- âœ… 4x plus rapide que Whisper standard
- âœ… Moins de RAM (~800MB vs ~1.5GB)
- âœ… 99+ langues dont franÃ§ais
- âœ… Fonctionne trÃ¨s bien sur Pi 5

### Installation:

```bash
source venv/bin/activate

# Installer faster-whisper
pip install faster-whisper

# Test rapide
python3 -c "
from faster_whisper import WhisperModel
print('âœ… Faster-Whisper installÃ©')
model = WhisperModel('tiny', device='cpu', compute_type='int8')
print('âœ… ModÃ¨le tiny chargÃ©')
"
```

### ModÃ¨les disponibles:

| ModÃ¨le | Taille | RAM | Vitesse | QualitÃ© |
|--------|--------|-----|---------|---------|
| **tiny** | 75 MB | ~800 MB | âš¡âš¡âš¡âš¡âš¡ | â­â­â­â­ |
| **base** | 145 MB | ~1 GB | âš¡âš¡âš¡âš¡ | â­â­â­â­ |
| **small** | 488 MB | ~2 GB | âš¡âš¡âš¡ | â­â­â­â­â­ |

**Recommandation Pi 5**: Utilisez **tiny** (rapide, bonne qualitÃ©)

### Test:

```bash
# CrÃ©er un fichier audio de test
espeak-ng -v fr -w test_question.wav "Comment activer Orange Money ?"

# Transcrire avec faster-whisper
python3 << 'EOF'
from faster_whisper import WhisperModel

model = WhisperModel("tiny", device="cpu", compute_type="int8")
segments, info = model.transcribe("test_question.wav", language="fr")

text = " ".join([segment.text for segment in segments])
print(f"Texte transcrit: {text}")
EOF
```

---

## ğŸ“¦ Option 2: OpenAI Whisper (Standard)

Le modÃ¨le original d'OpenAI, trÃ¨s bonne qualitÃ© mais plus lent.

### Installation:

```bash
source venv/bin/activate

# Installer whisper
pip install openai-whisper

# DÃ©pendances supplÃ©mentaires
sudo apt install ffmpeg

# Test
python3 -c "
import whisper
model = whisper.load_model('tiny')
print('âœ… Whisper installÃ© et prÃªt')
"
```

### Test:

```bash
python3 << 'EOF'
import whisper

model = whisper.load_model("tiny")
result = model.transcribe("test_question.wav", language="fr")
print(f"Texte: {result['text']}")
EOF
```

**Note**: Plus lent que faster-whisper, prÃ©fÃ©rez faster-whisper!

---

## ğŸ“¦ Option 3: Vosk (Ultra-LÃ©ger)

TrÃ¨s rapide mais qualitÃ© infÃ©rieure, idÃ©al si RAM limitÃ©e.

### Installation:

```bash
source venv/bin/activate

# Installer vosk
pip install vosk

# TÃ©lÃ©charger le modÃ¨le franÃ§ais
mkdir -p models
cd models

# ModÃ¨le small franÃ§ais (42MB)
wget https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip
unzip vosk-model-small-fr-0.22.zip
rm vosk-model-small-fr-0.22.zip

cd ..
```

### Test:

```bash
python3 << 'EOF'
from vosk import Model, KaldiRecognizer
import wave
import json

model = Model("models/vosk-model-small-fr-0.22")
wf = wave.open("test_question.wav", "rb")
rec = KaldiRecognizer(model, wf.getframerate())

results = []
while True:
    data = wf.readframes(4000)
    if len(data) == 0:
        break
    if rec.AcceptWaveform(data):
        result = json.loads(rec.Result())
        results.append(result.get("text", ""))

final = json.loads(rec.FinalResult())
results.append(final.get("text", ""))

print(f"Texte: {' '.join(results)}")
EOF
```

---

## ğŸš€ Lancer l'Assistant Vocal Complet

### Configurer le moteur STT:

Ã‰diter `data_processing/rag_server_voice.py` ligne 21:
```python
STT_ENGINE = "faster-whisper"  # ou "whisper" ou "vosk"
WHISPER_MODEL = "tiny"  # tiny, base, ou small
```

### DÃ©marrer le serveur:

```bash
source venv/bin/activate

# ArrÃªter les anciens serveurs
pkill -f uvicorn

# Lancer le serveur vocal
uvicorn data_processing.rag_server_voice:app --host 0.0.0.0 --port 8000
```

---

## ğŸ¯ Utilisation - Exemples API

### 1. Question Vocale â†’ RÃ©ponse Vocale

```bash
# Enregistrer une question (avec votre micro)
arecord -f cd -d 5 ma_question.wav

# Ou utiliser un fichier de test
espeak-ng -v fr -w ma_question.wav "Quels sont les forfaits internet disponibles?"

# Envoyer au serveur
curl -X POST http://localhost:8000/voice/ask \
  -F "audio=@ma_question.wav" \
  -F "language=fr" \
  -F "response_format=audio" \
  --output reponse.wav

# Ã‰couter la rÃ©ponse
aplay reponse.wav
```

### 2. Question Vocale â†’ RÃ©ponse Texte + Audio

```bash
curl -X POST http://localhost:8000/voice/ask \
  -F "audio=@ma_question.wav" \
  -F "language=fr" \
  -F "response_format=both" \
  | python3 -m json.tool
```

**RÃ©ponse:**
```json
{
  "question": "Quels sont les forfaits internet disponibles?",
  "response": "Les forfaits internet disponibles sont...",
  "language": "fr",
  "scores": [0.76, 0.74, 0.73],
  "audio_base64": "UklGRi4gAABXQVZF...",
  "audio_download_url": "/tts?text=..."
}
```

### 3. Transcription Seulement (STT)

```bash
curl -X POST http://localhost:8000/voice/transcribe \
  -F "audio=@ma_question.wav" \
  -F "language=fr"
```

**RÃ©ponse:**
```json
{
  "text": "Quels sont les forfaits internet disponibles?",
  "language": "fr",
  "engine": "faster-whisper"
}
```

### 4. Question Texte (mode classique)

```bash
curl -X POST http://localhost:8000/text/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Comment activer Orange Money?",
    "language": "fr",
    "enable_voice": true
  }'
```

---

## ğŸ¨ Interface Web avec Enregistrement Vocal

CrÃ©er `static/voice_assistant.html`:

```html
<!DOCTYPE html>
<html>
<head>
    <title>Assistant Vocal Orange</title>
    <meta charset="UTF-8">
    <style>
        body {
            font-family: Arial;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: linear-gradient(135deg, #ff7900 0%, #ff9500 100%);
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        }
        h1 { color: #ff7900; text-align: center; }
        button {
            padding: 15px 30px;
            font-size: 18px;
            margin: 10px;
            cursor: pointer;
            border-radius: 8px;
            border: none;
            background: #ff7900;
            color: white;
            transition: 0.3s;
        }
        button:hover { background: #ff9500; }
        button:disabled { background: #ccc; cursor: not-allowed; }
        #recordBtn.recording {
            background: #dc3545;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        #status {
            margin: 20px 0;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
            min-height: 50px;
        }
        #response {
            margin-top: 20px;
            padding: 20px;
            background: #e8f5e9;
            border-radius: 8px;
            display: none;
        }
        audio {
            width: 100%;
            margin-top: 15px;
        }
        .controls {
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸŠ Assistant Vocal Orange Burkina Faso</h1>

        <div class="controls">
            <button id="recordBtn">ğŸ¤ Enregistrer Question</button>
            <button id="stopBtn" disabled>â¹ï¸ ArrÃªter</button>
            <br>
            <label>Langue:</label>
            <select id="language">
                <option value="fr">FranÃ§ais</option>
                <option value="moore">MoorÃ©</option>
                <option value="dioula">Dioula</option>
            </select>
        </div>

        <div id="status">ğŸ’¡ Cliquez sur "Enregistrer" pour poser une question vocale</div>
        <div id="response"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];

        const recordBtn = document.getElementById('recordBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDiv = document.getElementById('status');
        const responseDiv = document.getElementById('response');
        const languageSelect = document.getElementById('language');

        recordBtn.onclick = async () => {
            audioChunks = [];

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);

            mediaRecorder.ondataavailable = (e) => {
                audioChunks.push(e.data);
            };

            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                await sendAudio(audioBlob);
            };

            mediaRecorder.start();

            recordBtn.disabled = true;
            recordBtn.classList.add('recording');
            stopBtn.disabled = false;
            statusDiv.innerHTML = 'ğŸ¤ Enregistrement en cours... Parlez maintenant!';
        };

        stopBtn.onclick = () => {
            mediaRecorder.stop();
            mediaRecorder.stream.getTracks().forEach(track => track.stop());

            recordBtn.disabled = false;
            recordBtn.classList.remove('recording');
            stopBtn.disabled = true;
            statusDiv.innerHTML = 'â³ Traitement de votre question...';
        };

        async function sendAudio(audioBlob) {
            const formData = new FormData();
            formData.append('audio', audioBlob, 'question.wav');
            formData.append('language', languageSelect.value);
            formData.append('response_format', 'both');

            try {
                const response = await fetch('http://localhost:8000/voice/ask', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();

                statusDiv.innerHTML = `
                    <strong>Question dÃ©tectÃ©e:</strong> ${data.question}
                `;

                responseDiv.innerHTML = `
                    <h3>RÃ©ponse:</h3>
                    <p>${data.response}</p>
                    <audio controls autoplay>
                        <source src="data:audio/wav;base64,${data.audio_base64}" type="audio/wav">
                    </audio>
                `;
                responseDiv.style.display = 'block';

            } catch (error) {
                statusDiv.innerHTML = `âŒ Erreur: ${error.message}`;
                responseDiv.style.display = 'none';
            }
        }
    </script>
</body>
</html>
```

### Utiliser l'interface:

```bash
# Option 1: Servir avec Python
cd static
python3 -m http.server 8080

# Option 2: Ajouter CORS au serveur
# Voir instructions ci-dessous

# Ouvrir dans le navigateur
# http://localhost:8080/voice_assistant.html
```

---

## ğŸ”§ Configuration CORS (pour interface web)

Ajouter CORS Ã  `rag_server_voice.py`:

```python
from fastapi.middleware.cors import CORSMiddleware

# AprÃ¨s app = FastAPI(...)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, spÃ©cifier les domaines
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

Puis:
```bash
pip install fastapi[standard]  # Inclut CORS
```

---

## ğŸ“Š Performances sur Raspberry Pi 5

### Avec Faster-Whisper (tiny) + TinyLlama + eSpeak:

```
Pipeline complet (Voice â†’ Voice):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. STT (Faster-Whisper tiny)   â”‚  ~2-4 secondes
â”‚ 2. FAISS Retrieval             â”‚  ~0.3 secondes
â”‚ 3. LLM (TinyLlama)             â”‚  ~3-6 secondes
â”‚ 4. TTS (eSpeak)                â”‚  ~0.1 secondes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
TOTAL: ~6-11 secondes âœ…
```

### Avec Faster-Whisper (tiny) + Phi-3-Mini + Piper:

```
Pipeline complet (Voice â†’ Voice):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. STT (Faster-Whisper tiny)   â”‚  ~2-4 secondes
â”‚ 2. FAISS Retrieval             â”‚  ~0.3 secondes
â”‚ 3. LLM (Phi-3-Mini)            â”‚  ~10-15 secondes
â”‚ 4. TTS (Piper)                 â”‚  ~1-2 secondes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
TOTAL: ~14-22 secondes âœ…
```

**Performance acceptable pour un assistant vocal!**

---

## ğŸŒ Support Langues Locales (MoorÃ©/Dioula)

### Statut Actuel:

- **STT**: Faster-Whisper transcrit en franÃ§ais (pas de modÃ¨le moorÃ©/dioula natif)
- **LLM**: Comprend le contexte mais rÃ©pond en franÃ§ais
- **TTS**: Utilise voix franÃ§aise

### Pour AmÃ©liorer:

1. **Fine-tuner Whisper** sur des audios en moorÃ©/dioula
2. **EntraÃ®ner un modÃ¨le LLM** bilingue franÃ§ais-moorÃ©
3. **CrÃ©er des voix TTS** personnalisÃ©es avec Piper

**Resources nÃ©cessaires**:
- 10-20 heures d'audio transcrit par langue
- GPU pour l'entraÃ®nement (ou cloud)
- 1-2 semaines de travail

---

## ğŸ™ï¸ Enregistrement Audio sur Pi 5

### Avec USB Microphone:

```bash
# Lister les devices audio
arecord -l

# Enregistrer 5 secondes
arecord -f cd -d 5 question.wav

# Enregistrer avec device spÃ©cifique
arecord -D plughw:1,0 -f cd -d 5 question.wav
```

### Avec Microphone intÃ©grÃ© (si disponible):

```bash
# Configurer le micro par dÃ©faut
nano ~/.asoundrc

# Ajouter:
pcm.!default {
    type asym
    playback.pcm "plughw:0,0"
    capture.pcm "plughw:1,0"
}
```

---

## âœ… Checklist d'Installation STT

- [ ] Faster-Whisper installÃ© et testÃ©
- [ ] ModÃ¨le `tiny` tÃ©lÃ©chargÃ© (automatique au premier usage)
- [ ] Test de transcription rÃ©ussi
- [ ] Serveur vocal lancÃ© (`rag_server_voice.py`)
- [ ] Test endpoint `/voice/ask`
- [ ] Test endpoint `/voice/transcribe`
- [ ] Interface web fonctionnelle (optionnel)
- [ ] Microphone configurÃ© sur Pi 5

---

## ğŸš€ Prochaines Ã‰tapes

1. **Tester sur Pi 5** avec microphone USB
2. **Optimiser les modÃ¨les** (choisir tiny/base/small selon besoins)
3. **CrÃ©er des raccourcis vocaux** ("Orange" pour activer)
4. **IntÃ©grer wake word detection** (Porcupine, Snowboy)
5. **Ajouter analytics** (logging des questions)

---

## ğŸ“š Ressources

- Faster-Whisper: https://github.com/guillaumekln/faster-whisper
- OpenAI Whisper: https://github.com/openai/whisper
- Vosk: https://alphacephei.com/vosk/
- ModÃ¨les Vosk: https://alphacephei.com/vosk/models
- Fine-tuning Whisper: https://huggingface.co/blog/fine-tune-whisper

---

**Votre assistant vocal est maintenant complet! ğŸ‰**

Parole â†’ Texte â†’ RAG â†’ RÃ©ponse â†’ Parole
