# üöÄ Quick Start - Raspberry Pi 5 Deployment

## TL;DR - 3 Commandes pour D√©marrer

```bash
# 1. Lancer l'installation automatique
./setup_pi5.sh

# 2. Activer l'environnement virtuel
source venv/bin/activate

# 3. D√©marrer le serveur
uvicorn data_processing.rag_server_pi:app --host 0.0.0.0 --port 8000
```

**C'est tout!** Votre serveur RAG est pr√™t √† r√©pondre aux questions.

---

## üìã Mod√®les Recommand√©s (100% Open Source & Gratuits)

| Mod√®le | Taille | RAM | Vitesse | Qualit√© | Id√©al pour |
|--------|--------|-----|---------|---------|------------|
| **Phi-3-Mini** ‚≠ê | 2.3 GB | ~3 GB | 5-8 tok/s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **Production** |
| **TinyLlama** | 0.6 GB | ~1 GB | 15-20 tok/s | ‚≠ê‚≠ê‚≠ê | Tests rapides |
| **Llama-3.2-3B** | 2.0 GB | ~2.5 GB | 6-10 tok/s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Balance |

**Tous sont gratuits, open-source, et fonctionnent offline!**

---

## üéØ Installation Manuelle (Si setup_pi5.sh ne fonctionne pas)

### 1. Installer les d√©pendances syst√®me
```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y python3-pip python3-venv cmake build-essential
```

### 2. Cr√©er environnement Python
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Installer packages Python
```bash
pip install llama-cpp-python
pip install fastapi uvicorn pydantic sentence-transformers faiss-cpu numpy psutil
```

### 4. T√©l√©charger un mod√®le

**Option A: Phi-3-Mini (RECOMMAND√â)**
```bash
wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf
```

**Option B: TinyLlama (Plus rapide)**
```bash
wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
```

### 5. Configurer le serveur
√âditer `data_processing/rag_server_pi.py` ligne 20:
```python
MODEL_PATH = "Phi-3-mini-4k-instruct-q4.gguf"  # Ou le nom de votre mod√®le
```

### 6. Lancer!
```bash
uvicorn data_processing.rag_server_pi:app --host 0.0.0.0 --port 8000
```

---

## ‚úÖ Tests

### Test 1: Health check
```bash
curl http://localhost:8000/health
```

**R√©ponse attendue:**
```json
{"status": "ok", "platform": "Raspberry Pi 5", "model": "Phi-3-mini-4k-instruct-q4.gguf"}
```

### Test 2: Statistiques RAM
```bash
curl http://localhost:8000/stats
```

### Test 3: Poser une question
```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Comment activer Orange Money?"}'
```

---

## üîß D√©marrage Automatique (Service Systemd)

### 1. Cr√©er le fichier service
```bash
sudo nano /etc/systemd/system/orange-rag.service
```

### 2. Copier cette configuration
```ini
[Unit]
Description=Orange RAG Chatbot Server
After=network.target

[Service]
Type=simple
User=suprox
WorkingDirectory=/home/suprox/Projet/Laravel/ai/orangebf
Environment="PATH=/home/suprox/Projet/Laravel/ai/orangebf/venv/bin"
ExecStart=/home/suprox/Projet/Laravel/ai/orangebf/venv/bin/uvicorn data_processing.rag_server_pi:app --host 0.0.0.0 --port 8000
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

### 3. Activer le service
```bash
sudo systemctl daemon-reload
sudo systemctl enable orange-rag
sudo systemctl start orange-rag

# V√©rifier le status
sudo systemctl status orange-rag

# Voir les logs
sudo journalctl -u orange-rag -f
```

**Le serveur d√©marrera automatiquement au boot du Pi!**

---

## üìä Performances Attendues

### Avec Phi-3-Mini Q4 sur Pi 5:
- **Temps de d√©marrage**: 30-60 secondes
- **RAM utilis√©e**: ~3 GB (sur 8 GB disponibles)
- **Vitesse de g√©n√©ration**: 5-8 tokens/seconde
- **Temps de r√©ponse**: 8-15 secondes par question
- **Qualit√©**: Excellente (comparable √† GPT-3.5)

### Avec TinyLlama Q4 sur Pi 5:
- **Temps de d√©marrage**: 10-15 secondes
- **RAM utilis√©e**: ~1 GB
- **Vitesse de g√©n√©ration**: 15-20 tokens/seconde
- **Temps de r√©ponse**: 3-6 secondes par question
- **Qualit√©**: Correcte (basique mais utilisable)

---

## üå°Ô∏è Monitoring

### V√©rifier la temp√©rature
```bash
vcgencmd measure_temp
```

**‚ö†Ô∏è Si >70¬∞C**: Installer un ventilateur actif

### Monitorer CPU/RAM en temps r√©el
```bash
htop
```

### V√©rifier l'utilisation disque
```bash
df -h
```

---

## üêõ Probl√®mes Courants

### Erreur: "Out of memory"
**Solution 1**: Utiliser TinyLlama au lieu de Phi-3
```bash
# T√©l√©charger TinyLlama
wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

# Modifier rag_server_pi.py
MODEL_PATH = "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
```

**Solution 2**: Augmenter le swap
```bash
sudo dphys-swapfile swapoff
sudo nano /etc/dphys-swapfile
# Changer: CONF_SWAPSIZE=4096
sudo dphys-swapfile setup
sudo dphys-swapfile swapon
```

### Erreur: "llama-cpp-python not found"
```bash
source venv/bin/activate
pip install llama-cpp-python --force-reinstall
```

### Le serveur est trop lent
**Solutions**:
1. R√©duire `max_tokens` dans `rag_server_pi.py` (ligne 70)
2. R√©duire `TOP_K` √† 2 (ligne 19)
3. Utiliser TinyLlama
4. Overclock le Pi (avec refroidissement!)

---

## üåê Acc√®s R√©seau

### Depuis votre ordinateur sur le m√™me r√©seau
```bash
# Trouver l'IP du Pi
hostname -I

# Acc√©der depuis un autre appareil
curl http://192.168.1.X:8000/health  # Remplacer X
```

### Depuis un navigateur web
Ouvrez: `http://192.168.1.X:8000/docs` pour l'interface Swagger

---

## üí° Conseils Pro

### 1. Garder le serveur actif avec tmux
```bash
# D√©marrer une session tmux
tmux new -s rag

# Lancer le serveur
source venv/bin/activate
uvicorn data_processing.rag_server_pi:app --host 0.0.0.0 --port 8000

# D√©tacher: Ctrl+B puis D
# R√©attacher plus tard: tmux attach -t rag
```

### 2. Logs en temps r√©el
```bash
# Si systemd service
sudo journalctl -u orange-rag -f

# Si tmux
tmux attach -t rag
```

### 3. Backup automatique des donn√©es
```bash
# Cr√©er un cron job pour backup
crontab -e

# Ajouter (backup quotidien √† 2h du matin)
0 2 * * * tar -czf /home/suprox/backup-$(date +\%Y\%m\%d).tar.gz /home/suprox/Projet/Laravel/ai/orangebf/*.json /home/suprox/Projet/Laravel/ai/orangebf/*.index
```

---

## üìö Documentation Compl√®te

- **Setup d√©taill√©**: `RASPBERRY_PI_SETUP.md`
- **Comparaison mod√®les**: `SOLUTION_COMPARISON.md`
- **Architecture du projet**: `CLAUDE.md`

---

## ‚ú® C'est Tout!

Votre chatbot RAG Orange Burkina Faso tourne maintenant sur votre Raspberry Pi 5!

**100% Open Source | 100% Gratuit | 100% Local | 100% Offline**

Pour toute question, consultez `RASPBERRY_PI_SETUP.md` pour plus de d√©tails.
